(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[515],{3077:(e,t,n)=>{Promise.resolve().then(n.bind(n,3452))},3452:(e,t,n)=>{"use strict";n.r(t),n.d(t,{default:()=>g});var s=n(5155),i=n(2115),r=n(6766);let a=e=>{let{children:t}=e;return(0,s.jsx)("div",{className:"w-full mb-5",children:(0,s.jsxs)("div",{className:"bg-white rounded-lg shadow-xl overflow-hidden",children:[(0,s.jsxs)("div",{className:"bg-gray-300 px-4 py-2.5 flex items-center justify-between border-b border-gray-400",children:[(0,s.jsxs)("div",{className:"flex items-center space-x-2",children:[(0,s.jsx)("div",{className:"w-3 h-3 bg-red-500 rounded-full border border-red-600 hover:bg-red-600 cursor-pointer"}),(0,s.jsx)("div",{className:"w-3 h-3 bg-yellow-500 rounded-full border border-yellow-600 hover:bg-yellow-600 cursor-pointer"}),(0,s.jsx)("div",{className:"w-3 h-3 bg-green-500 rounded-full border border-green-600 hover:bg-green-600 cursor-pointer"})]}),(0,s.jsx)("div",{})]}),t]})})},l=[{en:"Flappy Bird Game",zh:"Flappy Bird 游戏",uuid:"2a9a1a90-545b-4f29-b6ac-854539dcc323",url:"https://chat.z.ai/space/b0yb2613ybp0-art"},{en:"3D First Person Maze Runner",zh:"3D 第一人称迷宫奔跑者",uuid:"964d99e9-4756-4733-88ae-2c7814abb406",url:"https://chat.z.ai/space/z0sb56hrpna1-art"},{en:"TODO List with Drag and Search",zh:"带有拖拽和搜索功能的 TODO 看板",uuid:"b262f532-7b4d-4ed3-9a94-c9afad9f59c1",url:"https://chat.z.ai/space/t0ubc66pw1z0-art"},{en:"SVG Animation: Evolution of Language Models",zh:"SVG 动画：语言模型的演变",uuid:"6e4c7742-7a2d-469f-9dee-b1b35166efe4",children:'<svg viewBox="0 0 1200 600" xmlns="http://www.w3.org/2000/svg">\n  <defs>\n    \x3c!-- Gradients for different eras --\x3e\n    <linearGradient id="earlyGrad" x1="0%" y1="0%" x2="100%" y2="0%">\n      <stop offset="0%" style="stop-color:#8B4513;stop-opacity:1" />\n      <stop offset="100%" style="stop-color:#A0522D;stop-opacity:1" />\n    </linearGradient>\n    \n    <linearGradient id="statGrad" x1="0%" y1="0%" x2="100%" y2="0%">\n      <stop offset="0%" style="stop-color:#4682B4;stop-opacity:1" />\n      <stop offset="100%" style="stop-color:#5F9EA0;stop-opacity:1" />\n    </linearGradient>\n    \n    <linearGradient id="neuralGrad" x1="0%" y1="0%" x2="100%" y2="0%">\n      <stop offset="0%" style="stop-color:#9370DB;stop-opacity:1" />\n      <stop offset="100%" style="stop-color:#8A2BE2;stop-opacity:1" />\n    </linearGradient>\n    \n    <linearGradient id="transformerGrad" x1="0%" y1="0%" x2="100%" y2="0%">\n      <stop offset="0%" style="stop-color:#FF6347;stop-opacity:1" />\n      <stop offset="100%" style="stop-color:#FF4500;stop-opacity:1" />\n    </linearGradient>\n    \n    <linearGradient id="llmGrad" x1="0%" y1="0%" x2="100%" y2="0%">\n      <stop offset="0%" style="stop-color:#32CD32;stop-opacity:1" />\n      <stop offset="100%" style="stop-color:#228B22;stop-opacity:1" />\n    </linearGradient>\n    \n    \x3c!-- Glow effect --\x3e\n    <filter id="glow">\n      <feGaussianBlur stdDeviation="3" result="coloredBlur"/>\n      <feMerge>\n        <feMergeNode in="coloredBlur"/>\n        <feMergeNode in="SourceGraphic"/>\n      </feMerge>\n    </filter>\n  </defs>\n  \n  \x3c!-- Background --\x3e\n  <rect width="1200" height="600" fill="#0a0a0a"/>\n  \n  \x3c!-- Title --\x3e\n  <text x="600" y="40" text-anchor="middle" fill="white" font-size="28" font-weight="bold" opacity="0">\n    Evolution of Language Models\n    <animate attributeName="opacity" from="0" to="1" dur="1s" begin="0s" fill="freeze"/>\n  </text>\n  \n  \x3c!-- Main timeline --\x3e\n  <line x1="100" y1="300" x2="1100" y2="300" stroke="white" stroke-width="2" opacity="0">\n    <animate attributeName="opacity" from="0" to="0.3" dur="1s" begin="0.5s" fill="freeze"/>\n  </line>\n  \n  \x3c!-- Era 1: Early Rule-Based Systems (1950s-1960s) --\x3e\n  <g opacity="0">\n    <circle cx="150" cy="300" r="8" fill="url(#earlyGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="120" y="250" width="60" height="30" rx="5" fill="url(#earlyGrad)"/>\n    <text x="150" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">1950s</text>\n    <text x="150" y="330" text-anchor="middle" fill="white" font-size="14">Rule-Based</text>\n    <text x="150" y="350" text-anchor="middle" fill="white" font-size="12">Systems</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="1s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 2: ELIZA (1966) --\x3e\n  <g opacity="0">\n    <circle cx="250" cy="300" r="8" fill="url(#earlyGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" begin="0.2s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="220" y="250" width="60" height="30" rx="5" fill="url(#earlyGrad)"/>\n    <text x="250" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">1966</text>\n    <text x="250" y="330" text-anchor="middle" fill="white" font-size="14">ELIZA</text>\n    <text x="250" y="350" text-anchor="middle" fill="white" font-size="12">Chatbot</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="1.5s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 3: Statistical Methods (1980s-1990s) --\x3e\n  <g opacity="0">\n    <circle cx="350" cy="300" r="8" fill="url(#statGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" begin="0.4s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="320" y="250" width="60" height="30" rx="5" fill="url(#statGrad)"/>\n    <text x="350" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">1980s</text>\n    <text x="350" y="330" text-anchor="middle" fill="white" font-size="14">Statistical</text>\n    <text x="350" y="350" text-anchor="middle" fill="white" font-size="12">Methods</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="2s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 4: Word2Vec (2013) --\x3e\n  <g opacity="0">\n    <circle cx="450" cy="300" r="8" fill="url(#neuralGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" begin="0.6s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="420" y="250" width="60" height="30" rx="5" fill="url(#neuralGrad)"/>\n    <text x="450" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">2013</text>\n    <text x="450" y="330" text-anchor="middle" fill="white" font-size="14">Word2Vec</text>\n    <text x="450" y="350" text-anchor="middle" fill="white" font-size="12">Embeddings</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="2.5s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 5: Seq2Seq (2014) --\x3e\n  <g opacity="0">\n    <circle cx="550" cy="300" r="8" fill="url(#neuralGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" begin="0.8s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="520" y="250" width="60" height="30" rx="5" fill="url(#neuralGrad)"/>\n    <text x="550" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">2014</text>\n    <text x="550" y="330" text-anchor="middle" fill="white" font-size="14">Seq2Seq</text>\n    <text x="550" y="350" text-anchor="middle" fill="white" font-size="12">Models</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="3s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 6: Attention & Transformer (2017) --\x3e\n  <g opacity="0">\n    <circle cx="650" cy="300" r="12" fill="url(#transformerGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="12;18;12" dur="2s" begin="1s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="610" y="250" width="80" height="30" rx="5" fill="url(#transformerGrad)"/>\n    <text x="650" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">2017</text>\n    <text x="650" y="330" text-anchor="middle" fill="white" font-size="14">Attention &</text>\n    <text x="650" y="350" text-anchor="middle" fill="white" font-size="12">Transformer</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="3.5s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 7: BERT (2018) --\x3e\n  <g opacity="0">\n    <circle cx="750" cy="300" r="8" fill="url(#transformerGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" begin="1.2s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="720" y="250" width="60" height="30" rx="5" fill="url(#transformerGrad)"/>\n    <text x="750" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">2018</text>\n    <text x="750" y="330" text-anchor="middle" fill="white" font-size="14">BERT</text>\n    <text x="750" y="350" text-anchor="middle" fill="white" font-size="12">Pre-training</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="4s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 8: GPT Series (2018-2023) --\x3e\n  <g opacity="0">\n    <circle cx="850" cy="300" r="8" fill="url(#transformerGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" begin="1.4s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="820" y="250" width="60" height="30" rx="5" fill="url(#transformerGrad)"/>\n    <text x="850" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">2018+</text>\n    <text x="850" y="330" text-anchor="middle" fill="white" font-size="14">GPT</text>\n    <text x="850" y="350" text-anchor="middle" fill="white" font-size="12">Series</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="4.5s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 9: Large Language Models (2020s) --\x3e\n  <g opacity="0">\n    <circle cx="950" cy="300" r="12" fill="url(#llmGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="12;20;12" dur="2s" begin="1.6s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="910" y="250" width="80" height="30" rx="5" fill="url(#llmGrad)"/>\n    <text x="950" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">2020s</text>\n    <text x="950" y="330" text-anchor="middle" fill="white" font-size="14">Large Language</text>\n    <text x="950" y="350" text-anchor="middle" fill="white" font-size="12">Models</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="5s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Era 10: Future --\x3e\n  <g opacity="0">\n    <circle cx="1050" cy="300" r="8" fill="url(#llmGrad)" filter="url(#glow)">\n      <animate attributeName="r" values="8;12;8" dur="2s" begin="1.8s" repeatCount="indefinite"/>\n    </circle>\n    <rect x="1020" y="250" width="60" height="30" rx="5" fill="url(#llmGrad)"/>\n    <text x="1050" y="270" text-anchor="middle" fill="white" font-size="12" font-weight="bold">Future</text>\n    <text x="1050" y="330" text-anchor="middle" fill="white" font-size="14">AGI?</text>\n    <text x="1050" y="350" text-anchor="middle" fill="white" font-size="12">Beyond</text>\n    \n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="5.5s" fill="freeze"/>\n  </g>\n  \n  \x3c!-- Progress bar at bottom --\x3e\n  <rect x="100" y="500" width="0" height="10" rx="5" fill="url(#llmGrad)" opacity="0.8">\n    <animate attributeName="width" from="0" to="950" dur="6s" begin="0s" fill="freeze"/>\n  </rect>\n  \n  \x3c!-- Era labels with animations --\x3e\n  <text x="150" y="480" text-anchor="middle" fill="white" font-size="12" opacity="0">\n    Early Era\n    <animate attributeName="opacity" from="0" to="0.7" dur="0.5s" begin="1s" fill="freeze"/>\n  </text>\n  \n  <text x="350" y="480" text-anchor="middle" fill="white" font-size="12" opacity="0">\n    Statistical Era\n    <animate attributeName="opacity" from="0" to="0.7" dur="0.5s" begin="2s" fill="freeze"/>\n  </text>\n  \n  <text x="550" y="480" text-anchor="middle" fill="white" font-size="12" opacity="0">\n    Neural Era\n    <animate attributeName="opacity" from="0" to="0.7" dur="0.5s" begin="3s" fill="freeze"/>\n  </text>\n  \n  <text x="750" y="480" text-anchor="middle" fill="white" font-size="12" opacity="0">\n    Transformer Era\n    <animate attributeName="opacity" from="0" to="0.7" dur="0.5s" begin="4s" fill="freeze"/>\n  </text>\n  \n  <text x="950" y="480" text-anchor="middle" fill="white" font-size="12" opacity="0">\n    LLM Era\n    <animate attributeName="opacity" from="0" to="0.7" dur="0.5s" begin="5s" fill="freeze"/>\n  </text>\n  \n  \x3c!-- Animated particles for visual effect --\x3e\n  <circle cx="150" cy="300" r="2" fill="white" opacity="0">\n    <animate attributeName="cy" from="300" to="200" dur="3s" begin="1s" repeatCount="indefinite"/>\n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="1s" fill="freeze"/>\n  </circle>\n  \n  <circle cx="650" cy="300" r="2" fill="white" opacity="0">\n    <animate attributeName="cy" from="300" to="180" dur="3s" begin="3.5s" repeatCount="indefinite"/>\n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="3.5s" fill="freeze"/>\n  </circle>\n  \n  <circle cx="950" cy="300" r="2" fill="white" opacity="0">\n    <animate attributeName="cy" from="300" to="160" dur="3s" begin="5s" repeatCount="indefinite"/>\n    <animate attributeName="opacity" from="0" to="1" dur="0.5s" begin="5s" fill="freeze"/>\n  </circle>\n</svg>'},{en:"Python Simulation of Nested Spinning Hexagons",zh:"嵌套旋转六边形的 Python 模拟",uuid:"48d4a175-7757-44ea-b459-12eea185da81",video:"https://z-cdn.chatglm.cn/z-blog/artifact-1.mp4"},{en:"Beamer slides about Maxwell Equations",zh:"关于麦克斯韦方程组的 Beamer 幻灯片",uuid:"c85caa2e-adf5-4697-b03d-af59647fe637",pdf:"https://z-cdn.chatglm.cn/z-blog/maxwell.pdf"}];function c(e){let{language:t}=e,[n,c]=(0,i.useState)(0),[d,o]=(0,i.useState)(0),[h,x]=(0,i.useState)(!1);return(0,i.useEffect)(()=>{h||(x(!0),setInterval(()=>{var e,t,n,s;return o(null!=(s=null==(n=document.getElementById("artifacts-svg"))||null==(t=n.contentWindow)||null==(e=t.document.body)?void 0:e.scrollHeight)?s:0)},100),"application/pdf"in navigator.mimeTypes?l.forEach((e,t)=>{if(e.pdf){let n=document.getElementById("artifacts-pdf-".concat(t)),s=document.createElement("iframe");s.className="w-full h-[600px]",s.src=e.pdf,n.appendChild(s),n.className=""}}):(async()=>{let e=document.createElement("script");e.type="module",e.src="//unpkg.com/pdfjs-dist@5.4.54/build/pdf.min.mjs",document.head.appendChild(e);let{promise:t,resolve:n}=Promise.withResolvers();e.onload=()=>n(),await t;let s=window.pdfjsLib;s.GlobalWorkerOptions.workerSrc="//unpkg.com/pdfjs-dist@5.4.54/build/pdf.worker.min.mjs",l.forEach(async(e,t)=>{if(e.pdf){let n=document.getElementById("artifacts-pdf-".concat(t));n.querySelectorAll("canvas").forEach(e=>n.removeChild(e));let i=await s.getDocument(e.pdf).promise,r=Array(i.numPages).fill(0).map(()=>document.createElement("canvas"));r.forEach(e=>{e.classList.add("w-full"),n.appendChild(e)}),await Promise.all(r.map(async(e,t)=>{var n;let s=await i.getPage(t+1),r=s.getViewport({scale:null!=(n=window.devicePixelRatio)?n:2});return e.height=r.height,e.width=r.width,s.render({canvas:e,canvasContext:e.getContext("2d"),viewport:r}).promise}))}})})())},[]),(0,s.jsx)("div",{className:"max-w-[60rem] self-stretch full-width-container example-container",children:l.map((e,i)=>(0,s.jsxs)("div",{className:"example-content",style:{display:i===n?"block":"none"},children:[(0,s.jsxs)("div",{className:"title",children:[(0,s.jsxs)("div",{className:"flex flex-wrap items-center gap-1",children:[(0,s.jsxs)("span",{children:["Example: ",e[t]]}),(0,s.jsxs)("a",{className:"flex item-center bg-gray-200 gap-1 px-2 rounded-full text-md normal-case",href:"https://chat.z.ai/s/".concat(e.uuid),target:"_blank",style:{color:"gray"},children:["en"===t?"View full trajectory at Z.ai":"在 Z.ai 查看完整轨迹",(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/z-icon.svg",alt:"",height:16,width:16,style:{margin:0}})]})]}),(0,s.jsxs)("a",{className:"next-button whitespace-nowrap relative rounded-sm",onClick:e=>{e.preventDefault(),c(e=>(e+1)%l.length)},children:[(0,s.jsx)("div",{className:"absolute left-0 top-0 h-full bg-blue-400 rounded-sm",style:{width:"".concat((i+1)/l.length*100,"%"),zIndex:-1}}),"Next (",i+1," / ",l.length,")"]})]}),(0,s.jsx)("div",{className:"content",children:(0,s.jsx)("div",{className:"p-6 bg-gray-50",children:e.url?(0,s.jsxs)(a,{children:[(0,s.jsxs)("div",{className:"p-3 border-b border-gray-200 flex justify-between gap-2",children:[(0,s.jsxs)("div",{className:"left flex-1 flex gap-2 items-center text-xs",children:[(0,s.jsx)("button",{className:"p-1.5 rounded-md bg-black/5 hover:bg-black/10",onClick:()=>{let t=document.getElementById("artifact-example-".concat(i));t.src="about:blank",t.src=e.url},children:(0,s.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",fill:"none",viewBox:"0 0 24 24",strokeWidth:"1.5",stroke:"currentColor",className:"size-4",children:(0,s.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",d:"M16.023 9.348h4.992v-.001M2.985 19.644v-4.992m0 0h4.992m-4.993 0l3.181 3.183a8.25 8.25 0 0013.803-3.7M4.031 9.865a8.25 8.25 0 0113.803-3.7l3.181 3.182m0-4.991v4.99"})})}),(0,s.jsx)("button",{className:"p-1.5 rounded-md bg-black/5 hover:bg-black/10",onClick:()=>window.open(e.url,"_blank"),children:(0,s.jsxs)("svg",{className:"size-4",strokeWidth:"1.5",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg",xmlnsXlink:"http://www.w3.org/1999/xlink",width:"200",height:"200",children:[(0,s.jsx)("path",{d:"M664.896 359.104a35.2 35.2 0 0 1 8.512 36.032l-64 192a35.2 35.2 0 0 1-22.272 22.272l-192 64a35.2 35.2 0 0 1-44.544-44.544l64-192a35.2 35.2 0 0 1 22.272-22.272l192-64a35.2 35.2 0 0 1 36.032 8.512zM475.84 475.84L439.68 584.32l108.48-36.16 36.16-108.48-108.48 36.16z",fill:"currentColor"}),(0,s.jsx)("path",{d:"M512 819.2a307.2 307.2 0 1 0 0-614.4 307.2 307.2 0 0 0 0 614.4zM896 512A384 384 0 1 1 128 512a384 384 0 0 1 768 0z",fill:"currentColor"})]})})]}),(0,s.jsx)("input",{name:"url",className:"w-full border border-gray-200 rounded-sm px-2 py-1",value:e.url,disabled:!0})]}),(0,s.jsx)("div",{className:"p-6 bg-gray-50",children:(0,s.jsx)("iframe",{id:"artifact-example-".concat(i),className:"w-full h-[600px]",src:e.url})})]}):e.children?i===n&&(0,s.jsx)("iframe",{id:"artifacts-svg",className:"w-full",style:{height:d},srcDoc:e.children}):e.video?i===n&&(0,s.jsx)("figure",{className:"w-full h-fit",style:{margin:0},children:(0,s.jsx)("video",{src:e.video,controls:!0,loop:!0,autoPlay:!0})}):e.pdf?(0,s.jsx)("div",{className:"flex flex-col gap-2 max-h-[600px] overflow-y-scroll",id:"artifacts-pdf-".concat(i)}):void 0})})]},"example-".concat(i)))})}let d=[{en:"Tadej Pogačar's achievements",zh:"塔代伊\xb7波加查尔的成就",uuid:"e674f111-2f70-4df5-accc-98da4d498058"},{en:"PDF2PPT: ChatGLM's paper",zh:"PDF2PPT（ChatGLM 论文）",uuid:"92e21b4c-b8fd-4909-95b0-e26c814688e7"},{en:"Mona Lisa's inner monologue",zh:"蒙娜丽莎的内心独白",uuid:"9d6abba7-dd0b-47b6-a552-3aff87b81341"},{en:"The Big Bang Theory",zh:"海报（大爆炸理论）",uuid:"666f0626-b285-4722-aa21-98836f4c673a"},{en:"Pets Adoptions",zh:"海报（宠物领养）",uuid:"93defdcb-3902-4492-a72e-775331466eab"}];function o(e){var t,n;let{language:a}=e,[l,c]=(0,i.useState)(0),[o,h]=(0,i.useState)({}),[x,m]=(0,i.useState)([]),g=(0,i.useRef)(null),p=((null!=(n=null==(t=g.current)?void 0:t.clientWidth)?n:960)-50)/1280;return(0,i.useEffect)(()=>{d.forEach(e=>fetch("https://chat.z.ai/api/ppt/share/".concat(e.uuid,"?v=1")).then(e=>e.json()).then(t=>{var n;return(null==(n=t.slides)?void 0:n.pages)&&h(n=>({...n,[e.uuid]:t.slides.pages}))}))},[]),(0,i.useEffect)(()=>{let e=Array.from(document.querySelectorAll(".slides-creation-".concat(l,"-iframe"))).map(e=>{var t,n,s;return Math.max(null!=(s=null==(n=e.contentWindow)||null==(t=n.document.body)?void 0:t.scrollHeight)?s:0,720)});e.some((e,t)=>e!==x[t])&&m(e)}),(0,s.jsx)("div",{ref:g,className:"max-w-[60rem] self-stretch full-width-container example-container",children:d.map((e,t)=>{var n;return(0,s.jsxs)("div",{className:"example-content",style:{display:t===l?"block":"none"},children:[(0,s.jsxs)("div",{className:"title",children:[(0,s.jsxs)("div",{className:"flex flex-wrap items-start gap-1",children:[(0,s.jsxs)("span",{style:{maxWidth:"60%"},children:["Example: ",e[a]]}),(0,s.jsxs)("a",{className:"flex item-center bg-gray-200 gap-1 px-2 rounded-full text-md normal-case",href:"https://chat.z.ai/s/".concat(e.uuid),target:"_blank",style:{color:"gray"},children:["en"===a?"View full trajectory at Z.ai":"在 Z.ai 查看完整轨迹",(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/z-icon.svg",alt:"",height:16,width:16,style:{margin:0}})]})]}),(0,s.jsxs)("a",{className:"next-button whitespace-nowrap relative rounded-sm",onClick:e=>{e.preventDefault(),c(e=>(e+1)%d.length)},children:[(0,s.jsx)("div",{className:"absolute left-0 top-0 h-full bg-blue-400 rounded-sm",style:{width:"".concat((t+1)/d.length*100,"%"),zIndex:-1}}),"Next (",t+1," / ",d.length,")"]})]}),(0,s.jsx)("div",{className:"content",children:(0,s.jsx)("div",{className:"container @container max-w-full relative border-1 border-black/10 overflow-hidden max-h-[600px] overflow-y-scroll",children:(0,s.jsx)("div",{className:"flex flex-col p-6 gap-6 max-w-full",children:null==(n=o[e.uuid])?void 0:n.map((e,n)=>{var i;return(0,s.jsx)("div",{className:"bg-white w-full block overflow-hidden relative",style:{height:(null!=(i=x[n])?i:960)*p},children:(0,s.jsx)("iframe",{className:"w-[1280px] rounded-xl slides-creation-".concat(t,"-iframe"),title:"PPT",srcDoc:e,style:{transform:"scale(".concat(p,")"),transformOrigin:"left top",height:x[n]}})},n)})})})})]},"fullstack-example-".concat(t))})})}let h=[{en:"\uD83C\uDF1F Pok\xe9mon Pok\xe9dex Live",zh:"宝可梦",uuid:"f8c2f383-51d4-40b8-82e5-63529eaa00db",url:"https://x0nay6c3g7c1-deploy.space.z.ai"},{en:"\uD83D\uDCDA Medieval Poem Gen",zh:"中世纪诗歌生成器",uuid:"2aee0791-1d01-4b59-8f45-1a5bac46f6a1",url:"https://r0jac6mqda81-deploy.space.z.ai"},{en:"\uD83E\uDDE9 Cyberpunk Card AI Generator",zh:"赛博朋克卡牌生成",uuid:"4b0d2f79-f4fa-4607-aadf-c4514bb594a8 ",url:"https://v01bv6ubed21-deploy.space.z.ai"}];function x(e){let{language:t}=e,[n,l]=(0,i.useState)(0);return(0,s.jsx)("div",{className:"max-w-[60rem] self-stretch full-width-container example-container",children:h.map((e,i)=>(0,s.jsxs)("div",{className:"example-content",style:{display:i===n?"block":"none"},children:[(0,s.jsxs)("div",{className:"title",children:[(0,s.jsxs)("div",{className:"flex flex-wrap items-center gap-1",children:[(0,s.jsxs)("span",{children:["Example: ",e[t]]}),(0,s.jsxs)("a",{className:"flex item-center bg-gray-200 gap-1 px-2 rounded-full text-md normal-case",href:"https://chat.z.ai/s/".concat(e.uuid),target:"_blank",style:{color:"gray"},children:["en"===t?"View full trajectory at Z.ai":"在 Z.ai 查看完整轨迹",(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/z-icon.svg",alt:"",height:16,width:16,style:{margin:0}})]})]}),(0,s.jsxs)("a",{className:"next-button whitespace-nowrap relative rounded-sm",onClick:e=>{e.preventDefault(),l(e=>(e+1)%h.length)},children:[(0,s.jsx)("div",{className:"absolute left-0 top-0 h-full bg-blue-400 rounded-sm",style:{width:"".concat((i+1)/h.length*100,"%"),zIndex:-1}}),"Next (",i+1," / ",h.length,")"]})]}),(0,s.jsx)("div",{className:"content",children:(0,s.jsxs)(a,{children:[(0,s.jsxs)("div",{className:"p-3 border-b border-gray-200 flex justify-between gap-2",children:[(0,s.jsxs)("div",{className:"left flex-1 flex gap-2 items-center text-xs",children:[(0,s.jsx)("button",{className:"p-1.5 rounded-md bg-black/5 hover:bg-black/10",onClick:()=>{let t=document.getElementById("artifact-example-".concat(i));t.src="about:blank",t.src=e.url},children:(0,s.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",fill:"none",viewBox:"0 0 24 24",strokeWidth:"1.5",stroke:"currentColor",className:"size-4",children:(0,s.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",d:"M16.023 9.348h4.992v-.001M2.985 19.644v-4.992m0 0h4.992m-4.993 0l3.181 3.183a8.25 8.25 0 0013.803-3.7M4.031 9.865a8.25 8.25 0 0113.803-3.7l3.181 3.182m0-4.991v4.99"})})}),(0,s.jsx)("button",{className:"p-1.5 rounded-md bg-black/5 hover:bg-black/10",onClick:()=>window.open(e.url,"_blank"),children:(0,s.jsxs)("svg",{className:"size-4",strokeWidth:"1.5",viewBox:"0 0 1024 1024",version:"1.1",xmlns:"http://www.w3.org/2000/svg",xmlnsXlink:"http://www.w3.org/1999/xlink",width:"200",height:"200",children:[(0,s.jsx)("path",{d:"M664.896 359.104a35.2 35.2 0 0 1 8.512 36.032l-64 192a35.2 35.2 0 0 1-22.272 22.272l-192 64a35.2 35.2 0 0 1-44.544-44.544l64-192a35.2 35.2 0 0 1 22.272-22.272l192-64a35.2 35.2 0 0 1 36.032 8.512zM475.84 475.84L439.68 584.32l108.48-36.16 36.16-108.48-108.48 36.16z",fill:"currentColor"}),(0,s.jsx)("path",{d:"M512 819.2a307.2 307.2 0 1 0 0-614.4 307.2 307.2 0 0 0 0 614.4zM896 512A384 384 0 1 1 128 512a384 384 0 0 1 768 0z",fill:"currentColor"})]})})]}),(0,s.jsx)("input",{name:"url",className:"w-full border border-gray-200 rounded-sm px-2 py-1",value:e.url,disabled:!0})]}),(0,s.jsx)("div",{className:"p-6 bg-gray-50",children:(0,s.jsx)("iframe",{id:"fullstack-example-".concat(i),className:"w-full h-[600px]",src:e.url})})]})})]},"fullstack-example-".concat(i)))})}function m(e){let{language:t}=e;return"en"===t?(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"Today, we introduce two new GLM family members: GLM-4.5 and GLM-4.5-Air — our latest flagship models. GLM-4.5 is built with 355 billion total parameters and 32 billion active parameters, and GLM-4.5-Air with 106 billion total parameters and 12 billion active parameters. Both are designed to unify reasoning, coding, and agentic capabilities into a single model in order to satisfy more and more complicated requirements of fast rising agentic applications."}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["Both GLM-4.5 and GLM-4.5-Air are hybrid reasoning models, offering:"," ",(0,s.jsx)("em",{children:"thinking"})," mode for complex reasoning and tool using, and"," ",(0,s.jsx)("em",{children:"non-thinking"})," mode for instant responses. They are available on"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"}),","," ",(0,s.jsx)("a",{href:"https://docs.z.ai/guides/llm/glm-4.5",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai API"})," ","and open-weights are available at"," ",(0,s.jsx)("a",{href:"https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b",target:"_blank",className:"hover:text-gray-500 underline",children:"HuggingFace"})," ","and"," ",(0,s.jsx)("a",{href:"https://modelscope.cn/collections/GLM-45-b8693e2a08984f",target:"_blank",className:"hover:text-gray-500 underline",children:"ModelScope"}),"."]}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:[(0,s.jsx)("strong",{children:"Background:"})," LLM always targets at achieving human-level cognitive capabilities across a wide range of domains, rather than designed for specific tasks. As a good LLM model, it is necessary to deal with general problem solving, generalization, commen sense reasoning, and self-improvement. In the past five years, OpenAI's GPT-3 learns commen-sense knowledge, and o1 uses reinforcement learning to think before respond, significantly improving reasoning skills in coding, data analysis, and complex math. However, the resultant models are still not really general: some of them are good at coding, some good at math, and some good at reasoning, but none of them could achieve the best performance across all the different tasks. GLM-4.5 makes efforts toward the goal of unifying all the different capabilities."]}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"Overall Performance"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"We compare GLM-4.5 with various models from OpenAI, Anthropic, Google DeepMind, xAI, Alibaba, Moonshot, and DeepSeek on 12 benchmarks covering agentic (3), reasoning (7), and Coding (2). Overall, GLM-4.5 is ranked at the 3rd place and GLM-4.5 Air is ranked at the 6th."})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/20250729-141203.png",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"Agentic Tasks"})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"GLM-4.5 is a foundation model optimized for agentic tasks. It provides 128k context length and native function calling capacity. We measure its agent ability on τ-bench and BFCL-v3 (Berkeley Function Calling Leaderboard v3). On both benchmarks, GLM-4.5 matches the performance of Claude 4 Sonnet."})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/HJ4VZkBDxe.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsx)("div",{className:"flex flex-col items-center gap-4 pt-2",children:(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["Web browsing is a popular agentic application that requires complex reasoning and multi-turn tool using. We evaluate GLM-4.5 on the"," ",(0,s.jsx)("a",{href:"https://openai.com/index/browsecomp",target:"_blank",className:"hover:text-gray-500 underline",children:"BrowseComp"})," ","benchmark, a challenging benchmark for web browsing that consists of complicated questions that expect short answers. With access to the web browsing tool, GLM-4.5 gives correct answers for 26.4% of all questions, clearly outperforming Claude-4-Opus (18.8%) and close to o4-mini-high (28.3%). Below the figure shows the test-time scaling accuracy of GLM-4.5 on the BrowseComp."]})}),(0,s.jsx)("div",{className:"p-5 flex flex-col items-center max-w-[60rem]",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/HyiDl_Ewge.jpg",className:"rounded-lg bg-cover bg-center bg-no-repeat",style:{width:"50%"}})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"All the detailed results of different comparison models on the three Benchmarks used for eveluating model agent ability are listed in the following table."}),(0,s.jsx)("div",{style:{maxWidth:"min(60rem, 100vw)",overflowY:"scroll"},children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Benchmark"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5-Air"}),(0,s.jsx)("th",{children:"o3"}),(0,s.jsx)("th",{children:"o4-mini-high"}),(0,s.jsx)("th",{children:"GPT-4.1"}),(0,s.jsx)("th",{children:"Claude 4 Opus"}),(0,s.jsx)("th",{children:"Claude 4 Sonnet"}),(0,s.jsx)("th",{children:"Gemini 2.5 Pro"}),(0,s.jsx)("th",{children:"Qwen3 235B Thinking 2507"}),(0,s.jsx)("th",{children:"DeepSeek-R1-0528"}),(0,s.jsx)("th",{children:"DeepSeek V3 0324"}),(0,s.jsx)("th",{children:"Kimi K2"}),(0,s.jsx)("th",{children:"Grok 4"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"TAU-bench-Retail"}),(0,s.jsx)("td",{className:"highlight",children:"79.7"}),(0,s.jsx)("td",{className:"highlight",children:"77.9"}),(0,s.jsx)("td",{children:"70.4"}),(0,s.jsx)("td",{children:"65.6"}),(0,s.jsx)("td",{children:"75.1"}),(0,s.jsx)("td",{children:"81.4"}),(0,s.jsx)("td",{children:"80.5"}),(0,s.jsx)("td",{children:"77.0"}),(0,s.jsx)("td",{children:"71.9"}),(0,s.jsx)("td",{children:"63.9"}),(0,s.jsx)("td",{children:"74.7"}),(0,s.jsx)("td",{children:"73.9"}),(0,s.jsx)("td",{children:"76.5"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"TAU-bench-Airline"}),(0,s.jsx)("td",{className:"highlight",children:"60.4"}),(0,s.jsx)("td",{className:"highlight",children:"60.8"}),(0,s.jsx)("td",{children:"52.0"}),(0,s.jsx)("td",{children:"49.2"}),(0,s.jsx)("td",{children:"48.8"}),(0,s.jsx)("td",{children:"59.6"}),(0,s.jsx)("td",{children:"60.0"}),(0,s.jsx)("td",{children:"48.0"}),(0,s.jsx)("td",{children:"58.0"}),(0,s.jsx)("td",{children:"53.5"}),(0,s.jsx)("td",{children:"40.4"}),(0,s.jsx)("td",{children:"51.2"}),(0,s.jsx)("td",{children:"58.4"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"BFCL v3 (Full)"}),(0,s.jsx)("td",{className:"highlight",children:"77.8"}),(0,s.jsx)("td",{className:"highlight",children:"76.4"}),(0,s.jsx)("td",{children:"72.4"}),(0,s.jsx)("td",{children:"67.2"}),(0,s.jsx)("td",{children:"68.9"}),(0,s.jsx)("td",{children:"74.4"}),(0,s.jsx)("td",{children:"75.2"}),(0,s.jsx)("td",{children:"61.2"}),(0,s.jsx)("td",{children:"71.9"}),(0,s.jsx)("td",{children:"63.8"}),(0,s.jsx)("td",{children:"64.7"}),(0,s.jsx)("td",{children:"71.1"}),(0,s.jsx)("td",{children:"66.2"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"BrowseComp"}),(0,s.jsx)("td",{className:"highlight",children:"26.4"}),(0,s.jsx)("td",{className:"highlight",children:"21.3"}),(0,s.jsx)("td",{children:"49.7"}),(0,s.jsx)("td",{children:"28.3"}),(0,s.jsx)("td",{children:"4.1"}),(0,s.jsx)("td",{children:"18.8"}),(0,s.jsx)("td",{children:"14.7"}),(0,s.jsx)("td",{children:"7.6"}),(0,s.jsx)("td",{children:"4.6"}),(0,s.jsx)("td",{children:"3.2"}),(0,s.jsx)("td",{children:"1.5"}),(0,s.jsx)("td",{children:"7.9"}),(0,s.jsx)("td",{children:"32.6"})]})]})]})}),(0,s.jsx)("blockquote",{className:"max-w-[60rem] self-stretch font-poppins text-base font-normal leading-7 border-l-4 border-gray-400 pl-4 italic text-gray-600",children:(0,s.jsx)("p",{children:"For TAU-bench, we use an optimized user simulator for both Retail and Airline domains. The user prompt we use can be found in Appendix."})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"Reasoning"})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"Under the thinking mode, GLM-4.5 and GLM-4.5-Air can solve complex reasoning problems including mathematics, science, and logical problems."}),(0,s.jsx)("div",{style:{maxWidth:"min(60rem, 100vw)",overflowY:"scroll"},children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Benchmark"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5-Air"}),(0,s.jsx)("th",{children:"o3"}),(0,s.jsx)("th",{children:"Claude 4 Opus"}),(0,s.jsx)("th",{children:"Gemini 2.5 Pro"}),(0,s.jsx)("th",{children:"DeepSeek-R1-0528"}),(0,s.jsx)("th",{children:"Qwen3-235B-Thinking 2507"}),(0,s.jsx)("th",{children:"Grok 4"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"MMLU Pro"}),(0,s.jsx)("td",{className:"highlight",children:"84.6"}),(0,s.jsx)("td",{className:"highlight",children:"81.4"}),(0,s.jsx)("td",{children:"85.3"}),(0,s.jsx)("td",{children:"87.3"}),(0,s.jsx)("td",{children:"86.2"}),(0,s.jsx)("td",{children:"84.9"}),(0,s.jsx)("td",{children:"84.5"}),(0,s.jsx)("td",{children:"86.6"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"AIME24"}),(0,s.jsx)("td",{className:"highlight",children:"91.0"}),(0,s.jsx)("td",{className:"highlight",children:"89.4"}),(0,s.jsx)("td",{children:"90.3"}),(0,s.jsx)("td",{children:"75.7"}),(0,s.jsx)("td",{children:"88.7"}),(0,s.jsx)("td",{children:"89.3"}),(0,s.jsx)("td",{children:"94.1"}),(0,s.jsx)("td",{children:"94.3"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"MATH 500"}),(0,s.jsx)("td",{className:"highlight",children:"98.2"}),(0,s.jsx)("td",{className:"highlight",children:"98.1"}),(0,s.jsx)("td",{children:"99.2"}),(0,s.jsx)("td",{children:"98.2"}),(0,s.jsx)("td",{children:"96.7"}),(0,s.jsx)("td",{children:"98.3"}),(0,s.jsx)("td",{children:"98.0"}),(0,s.jsx)("td",{children:"99.0"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"SciCode"}),(0,s.jsx)("td",{className:"highlight",children:"41.7"}),(0,s.jsx)("td",{className:"highlight",children:"37.3"}),(0,s.jsx)("td",{children:"41.0"}),(0,s.jsx)("td",{children:"39.8"}),(0,s.jsx)("td",{children:"42.8"}),(0,s.jsx)("td",{children:"40.3"}),(0,s.jsx)("td",{children:"42.9"}),(0,s.jsx)("td",{children:"45.7"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"GPQA"}),(0,s.jsx)("td",{className:"highlight",children:"79.1"}),(0,s.jsx)("td",{className:"highlight",children:"75.0"}),(0,s.jsx)("td",{children:"82.7"}),(0,s.jsx)("td",{children:"79.6"}),(0,s.jsx)("td",{children:"84.4"}),(0,s.jsx)("td",{children:"81.3"}),(0,s.jsx)("td",{children:"81.1"}),(0,s.jsx)("td",{children:"87.7"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"HLE"}),(0,s.jsx)("td",{className:"highlight",children:"14.4"}),(0,s.jsx)("td",{className:"highlight",children:"10.6"}),(0,s.jsx)("td",{children:"20.0"}),(0,s.jsx)("td",{children:"11.7"}),(0,s.jsx)("td",{children:"21.1"}),(0,s.jsx)("td",{children:"14.9"}),(0,s.jsx)("td",{children:"15.8"}),(0,s.jsx)("td",{children:"23.9"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"LiveCodeBench (2407-2501)"}),(0,s.jsx)("td",{className:"highlight",children:"72.9"}),(0,s.jsx)("td",{className:"highlight",children:"70.7"}),(0,s.jsx)("td",{children:"78.4"}),(0,s.jsx)("td",{children:"63.6"}),(0,s.jsx)("td",{children:"80.1"}),(0,s.jsx)("td",{children:"77.0"}),(0,s.jsx)("td",{children:"78.2"}),(0,s.jsx)("td",{children:"81.9"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"AA-Index (Estimated)"}),(0,s.jsx)("td",{className:"highlight",children:"67.7"}),(0,s.jsx)("td",{className:"highlight",children:"64.8"}),(0,s.jsx)("td",{children:"70.0"}),(0,s.jsx)("td",{children:"64.4"}),(0,s.jsx)("td",{children:"70.5"}),(0,s.jsx)("td",{children:"68.3"}),(0,s.jsx)("td",{children:"69.4"}),(0,s.jsx)("td",{children:"73.2"})]})]})]})}),(0,s.jsx)("blockquote",{className:"max-w-[60rem] self-stretch font-poppins text-base font-normal leading-7 border-l-4 border-gray-400 pl-4 italic text-gray-600",children:(0,s.jsx)("p",{children:"For the AIME and GPQA benchmarks, we report the average accuracy over 32 and 8 samples respectively (Avg@32, Avg@8) to mitigate result variance. An LLM was used for automated answer validation. For the HLE benchmark, only the text-based questions were evaluated, with correctness judged by gpt-4o."})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"Coding"})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["GLM-4.5 excels at coding, including both building coding projects from scratch and agentically solving coding tasks in existing projects. It can be seamlessly combined with existing coding toolkits such as"," ",(0,s.jsx)("a",{href:"https://github.com/anthropics/claude-code",target:"_blank",className:"hover:text-gray-500 underline",children:"Claude Code"}),","," ",(0,s.jsx)("a",{href:"https://github.com/RooCodeInc/Roo-Code",target:"_blank",className:"hover:text-gray-500 underline",children:"Roo Code"}),", and"," ",(0,s.jsx)("a",{href:"https://codegeex.cn/",target:"_blank",className:"hover:text-gray-500 underline",children:"CodeGeex"}),". To evaluate the coding capability, we compared different models on SWE-bench Verified and Terminal Bench. The following table presents the results."]}),(0,s.jsx)("div",{style:{maxWidth:"min(60rem, 100vw)",overflowY:"scroll"},children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"Benchmark"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5-Air"}),(0,s.jsx)("th",{children:"o3"}),(0,s.jsx)("th",{children:"GPT-4.1"}),(0,s.jsx)("th",{children:"Claude 4 Opus"}),(0,s.jsx)("th",{children:"Claude 4 Sonnet"}),(0,s.jsx)("th",{children:"Gemini 2.5 Pro"}),(0,s.jsx)("th",{children:"DeepSeek-R1-0528"}),(0,s.jsx)("th",{children:"Kimi K2"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsxs)("td",{children:["SWE-bench Verified",(0,s.jsx)("sup",{children:"1"})]}),(0,s.jsx)("td",{className:"highlight",children:"64.2"}),(0,s.jsx)("td",{className:"highlight",children:"57.6"}),(0,s.jsx)("td",{children:"69.1"}),(0,s.jsx)("td",{children:"48.6"}),(0,s.jsx)("td",{children:"67.8"}),(0,s.jsx)("td",{children:"70.4"}),(0,s.jsx)("td",{children:"49.0"}),(0,s.jsx)("td",{children:"41.4"}),(0,s.jsx)("td",{children:"65.4"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsxs)("td",{children:["Terminal-Bench",(0,s.jsx)("sup",{children:"2"})]}),(0,s.jsx)("td",{className:"highlight",children:"37.5"}),(0,s.jsx)("td",{className:"highlight",children:"30"}),(0,s.jsx)("td",{children:"30.2"}),(0,s.jsx)("td",{children:"30.3"}),(0,s.jsx)("td",{children:"43.2"}),(0,s.jsx)("td",{children:"35.5"}),(0,s.jsx)("td",{children:"25.3"}),(0,s.jsx)("td",{children:"17.5"}),(0,s.jsx)("td",{children:"25.0"})]})]})]})}),(0,s.jsxs)("blockquote",{className:"max-w-[60rem] self-stretch font-poppins text-base font-normal leading-7 border-l-4 border-gray-400 pl-4 italic text-gray-600",children:[(0,s.jsxs)("p",{children:[(0,s.jsx)("sup",{children:"1"})," For SWE-bench Verified, we use OpenHands v0.34.0 with runs limited to 100 iterations and history truncation to prevent exceeding the 128K context limit, configured with temperature=0.6, top_p=1.0."]}),(0,s.jsxs)("p",{children:[(0,s.jsx)("sup",{children:"2"})," For Terminal-Bench, we use the Terminus framework for evaluation. We use standard function calling rather than direct prompting for evaluation."]})]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"We conducted a Pareto Frontier analysis for all comparison models (as illustrated in the figure below). GLM-4.5 and GLM-4.5-Air demonstrate superior performance relative to models of comparable scale, achieving optimal efficiency on the performance-scale trade-off boundary."})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/S1tGskrPge.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsx)("div",{className:"flex flex-col items-center gap-4 pt-2",children:(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"GLM-4.5 demonstrates comprehensive full-stack development capabilities, enabling seamless creation of web applications that encompass frontend implementation, database management, and backend deployment. The frontend interfaces generated by GLM-4.5 exhibit enhanced functionality and aesthetic appeal, demonstrating strong alignment with human design preferences. Furthermore, GLM-4.5 exhibits superior performance in generating presentation materials, including slides and posters, with capabilities significantly augmented when integrated with agentic tools for information retrieval and contextual enhancement."})}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/ByZG-kBvgg.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsx)("div",{className:"flex flex-col items-center gap-4 pt-2",children:(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"To assess GLM-4.5's agentic coding capabilities, we utilized Claude Code to evaluate performance against Claude-4-Sonnet, Kimi K2, and Qwen3-Coder across 52 coding tasks spanning frontend development, tool development, data analysis, testing, and algorithm implementation. All evaluations were performed in isolated testing environments through multi-round human interaction with standardized evaluation criteria to ensure consistency and reproducibility. The empirical results demonstrate that GLM-4.5 achieves a 53.9% win rate against Kimi K2 and exhibits dominant performance over Qwen3-Coder with an 80.8% success rate. While GLM-4.5 shows competitive performance, further optimization opportunities remain when compared to Claude-4-Sonnet."})}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/H1jQbyHvlx.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["Notably, GLM-4.5 achieves the highest average tool calling success rate at 90.6%, outperforming Claude-4-Sonnet (89.5%), Kimi-K2 (86.2%), and Qwen3-Coder (77.1%), demonstrating superior reliability and efficiency in agentic coding tasks. The trajectories of all 52 coding tasks are publicly available"," ",(0,s.jsx)("a",{href:"https://huggingface.co/datasets/zai-org/CC-Bench-trajectories",target:"_blank",className:"hover:text-gray-500 underline",children:"here"})," ","for further community study."]}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"Demos"}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"Artifacts"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"GLM-4.5 enhances the complex code generation capabilities introduced in the April release of GLM-4. The model now creates sophisticated standalone artifacts—from interactive mini-games to physics simulations—across HTML, SVG, Python and other formats. These improvements deliver superior user experiences while laying the foundation for advanced agentic coding applications."}),(0,s.jsx)(c,{language:t}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"Slides Creation"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"Leveraging GLM-4.5's powerful agentic tool usage and HTML coding capabilities, we developed a model-native PPT/Poster agent. Users can request simple or complex designs, or upload documents, the agent autonomously searches the web or retrieves images, then creates the slides."}),(0,s.jsx)(o,{language:t}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"Full Stack Development"}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["GLM-4.5 excels in both frontend and backend development, making it powerful for building modern web applications. To better demonstrate its capabilities, we develop a coding agent inspired by Claude Code. By providing a basic full-stack website boilerplate, the agent enables users to create an entire website with just a few words. Users can effortlessly add features and refine their projects through multi-turn dialogue, making the coding process smooth and enjoyable. Just relax, and let GLM-4.5 turn your ideas into reality at"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"}),"."]}),(0,s.jsx)(x,{language:t}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"Getting started with GLM-4.5"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsxs)("strong",{children:["Chat with GLM-4.5 on"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"})]})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["GLM-4.5 is accessible through the"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"})," ","platform by selecting the GLM-4.5 model option. The platform provides comprehensive support for artifacts generation, presentation slide creation, and full-stack development capabilities.",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"}),"."]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsxs)("strong",{children:["Call GLM-4.5 API on"," ",(0,s.jsx)("a",{href:"https://docs.z.ai/guides/llm/glm-4.5",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai API"})]})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["The"," ",(0,s.jsx)("a",{href:"https://docs.z.ai/guides/llm/glm-4.5",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai API platform"})," ","offers OpenAI-compatible interfaces for both GLM-4.5 and GLM-4.5-Air models. For comprehensive API documentation and integration guidelines, please refer to"," ",(0,s.jsx)("a",{href:"https://docs.z.ai/guides/llm/glm-4.5",target:"_blank",className:"hover:text-gray-500 underline",children:"https://docs.z.ai/guides/llm/glm-4.5"}),"."]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"Use GLM-4.5 with Coding Agents"})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["Detailed instructions for integrating GLM-4.5 with Claude Code and other coding agent frameworks are available in the documentation at"," ",(0,s.jsx)("a",{href:"https://docs.z.ai/scenario-example/develop-tools/claude",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai API"}),"."]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"Serve GLM-4.5 Locally"})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["Model weights for both base and chat variants of GLM-4.5 and GLM-4.5-Air are publicly available on"," ",(0,s.jsx)("a",{href:"https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b",target:"_blank",className:"hover:text-gray-500 underline",children:"HuggingFace"})," ","and"," ",(0,s.jsx)("a",{href:"https://modelscope.cn/collections/GLM-45-b8693e2a08984f",target:"_blank",className:"hover:text-gray-500 underline",children:"ModelScope"}),". For local deployment, GLM-4.5 supports inference frameworks including vLLM and SGLang. Comprehensive deployment instructions are available in the official"," ",(0,s.jsx)("a",{href:"https://github.com/zai-org/GLM-4.5",target:"_blank",className:"hover:text-gray-500 underline",children:"GitHub repository"}),"."]}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"Techniques"}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"Model Architecture & Pre-training"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"In the GLM-4.5 series, we adopt the MoE architecture, which improves the compute efficiency of both training and inference. We employ loss-free balance routing and sigmoid gates for MoE layers. Unlike DeepSeek-V3 and Kimi K2, we reduce the width (hidden dimension and number of routed experts) of the model while increasing the height (number of layers), as we found that deeper models exhibit better reasoning capacity. In the self-attention component, we employ Grouped-Query Attention with partial RoPE. Furthermore, we utilize 2.5 times more attention heads (96 heads for a 5120 hidden dimension). Counterintuitively, while this increased head count does not improve the training loss compared to models with fewer heads, it consistently enhances performance on reasoning benchmarks such as MMLU and BBH. For GLM-4.5, we utilize the Muon optimizer, which accelerates convergence and tolerates a larger batch size. We also incorporate QK-Norm to stabilize the range of attention logits. For both GLM-4.5 and GLM-4.5-Air, we add an MTP (Multi-Token Prediction) layer to support speculative decoding during inference."})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/SyDLepVveg.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"Our base model undergoes several training stages. During pre-training, the model is first trained on 15T tokens of a general pre-training corpus, followed by 7T tokens of a code & reasoning corpus. After pre-training, we introduce additional stages to further enhance the model's performance on key downstream domains. Unlike the earlier pre-training stage on large-scale universal documents, these stages leverage medium-sized domain-specific datasets, including instruction data."}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"RL for Large-Scale Models with slime"})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/B1pJ-JSvxx.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["To facilitate the highly efficient Reinforcement Learning (RL) training required for large-scale models such as GLM-4.5, we have designed, developed, and open-sourced"," ",(0,s.jsx)("a",{href:"https://github.com/THUDM/slime",target:"_blank",className:"hover:text-gray-500 underline",children:(0,s.jsx)("strong",{children:"slime"})}),". This RL infrastructure is engineered for exceptional flexibility, efficiency, and scalability, and we actively encourage community use and contributions."]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"slime's primary innovations are architected to overcome common RL bottlenecks, particularly in complex agentic tasks."}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:[" ","• ",(0,s.jsx)("strong",{children:"Flexible Hybrid Training Architecture:"})," slime’s core strength is its versatile hybrid architecture. It supports both synchronous, co-located training, ideal for traditional applications like Reasoning and General RL, as well as a disaggregated, asynchronous training mode. This asynchronous paradigm is critical for advanced agentic RL, where data generation can be a slow, external process. By decoupling training from data collection, it ensures our training GPUs remain fully saturated, maximizing hardware utilization.",(0,s.jsx)("br",{})," • ",(0,s.jsx)("strong",{children:"Decoupled Agent-Oriented Design:"})," Agentic RL often suffers from slow and long-tail latency distributions during environment rollouts, which severely throttles training throughput. To address this, slime implements a fully decoupled infrastructure that separates rollout engines from training engines. These components operate independently on distinct hardware, transforming the data generation bottleneck into a parallelized, non-blocking process. This design is fundamental to accelerating long-horizon agent tasks.",(0,s.jsx)("br",{})," •"," ",(0,s.jsx)("strong",{children:"Accelerated Data Generation with Mixed Precision:"})," ","To further boost throughput, slime features accelerated rollouts using mixed-precision inference. It strategically employs the highly efficient FP8 format for data generation while retaining the stability of BF16 for the model training loop. This technique dramatically increases data generation speed without compromising training quality."]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"This cohesive design allows slime to seamlessly integrate multiple agent frameworks, support diverse tasks, and efficiently manage long-horizon rollouts through a unified, powerful interface."}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"Post-Training with Reinforcement Learning for Agentic Capabilities"}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["The post-training is crucial for LLMs to iteratively enhance their policies through self-generated exploratory experiences. Reinforcement Learning (RL) has been a pivotal step to push the boundary of model capabilities. For GLM-4.5, in addition to integrating the general capabilities from GLM-4-0414 and reasoning from GLM-Z1, we paticularly enhance the agentic capabilities, including agentic coding, deep search, and general tool-using."," "]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"The process begins with supervised fine-tuning on curated reasoning data and synthesized agentic scenarios, followd by a specialized RL phase to cultivate expert models, respectively."}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["• For reasoning, we conduct a single-stage RL over the full 64K context with a difficulty-based curriculum, which we found superior to progressive scheduling. We introduced modified techniques to RL ensure stability: dynamic sampling temperatures to balance exploration-exploitation and adaptive clipping for robust policy updates on STEM problems.",(0,s.jsx)("br",{})," • For agentic tasks, the training is running on two verifiable tasks: information-seeking based QA and software-engineering. We develop scalable strategies to synthesize search-based QA pairs based human-in-the-loop extraction and selective obfuscation of content from web page. The coding tasks are driven by execution-based feedback on real-world SWE tasks."]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"Although the RL curriculum targets a limited set of verified tasks, the resulting gains transfer to adjacent abilities such as general tool use. Next, expert distillation consolidates these specialized skills, equipping GLM-4.5 with comprehensive strength across all tasks."}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"Appendix"}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"Optimized User Simulator for TAU-Bench"})]}),(0,s.jsxs)("pre",{className:"text-sm bg-card-background p-2 rounded-lg text-left font-mono whitespace-pre-wrap max-w-[60rem] mx-5",children:['user_prompt = f"""You are a user interacting with an agent.',"{instruction_display}",(0,s.jsx)("br",{}),"# Rules:",(0,s.jsx)("br",{}),"- Just generate one line at a time to simulate the user's message.",(0,s.jsx)("br",{}),"- Do not give away all the instruction at once. Only provide the information that is necessary for the current step.",(0,s.jsx)("br",{}),"- Do not hallucinate information that is not provided in the instruction. Follow these guidelines:",(0,s.jsx)("br",{})," 1. If the agent asks for information NOT in the instruction:",(0,s.jsx)("br",{})," - Say you don't remember or don't have it",(0,s.jsx)("br",{})," - Offer alternative information that IS mentioned in the instruction",(0,s.jsx)("br",{})," 2. Examples:",(0,s.jsx)("br",{}),' - If asked for order ID (not in instruction): "Sorry, I don\'t remember the order ID, can you search for it? My name/email/phone number/zipcode is ..."',(0,s.jsx)("br",{}),' - If asked for email (not in instruction): "I don\'t have my email handy, but I can give you my name and zip code which are..."',(0,s.jsx)("br",{}),"- Do not repeat the exact instruction in the conversation. Instead, use your own words to convey the same information.",(0,s.jsx)("br",{}),"- Try to make the conversation as natural as possible, and stick to the personalities in the instruction.",(0,s.jsx)("br",{}),"# Constraint Handling:",(0,s.jsx)("br",{}),"- Provide requests strictly based on what is explicitly stated in the instruction.",(0,s.jsx)("br",{}),"- Do not assume, extend, substitute, or generalize in any form.",(0,s.jsx)("br",{}),"- Do not modify or relax constraints on:",(0,s.jsx)("br",{}),"- Time / Date",(0,s.jsx)("br",{}),"- Budget",(0,s.jsx)("br",{}),'- Specific terms (e.g., "same" must not be replaced with "similar")',(0,s.jsx)("br",{}),"- Core Rule: Any attribute NOT mentioned in the instruction can be either changed or kept the same",(0,s.jsx)("br",{}),"- Examples:",(0,s.jsx)("br",{}),' - If instruction says "exchange red item to blue": Only color must change, other attributes (size, material, etc.) are flexible',(0,s.jsx)("br",{}),' - If instruction says "exchange red item to blue, keep the same size": Both color must change AND size must stay the same',(0,s.jsx)("br",{}),"- Exception: Only follow additional constraints when explicitly stated in the instruction",(0,s.jsx)("br",{}),"# When NOT to finish the conversation:",(0,s.jsx)("br",{}),"- Do not end until you have clearly and completely expressed all your requirements and constraints.",(0,s.jsx)("br",{}),"- Do not end until the agent has completed all tasks mentioned in the instruction and verified no operations were missed.",(0,s.jsx)("br",{}),"- Do not end if the agent's execution results do not match your expectations or are incorrect/incomplete.",(0,s.jsx)("br",{}),"# When you CAN finish the conversation:",(0,s.jsx)("br",{}),"- Only when all above conditions are satisfied AND all tasks are completed correctly.",(0,s.jsx)("br",{}),"- OR when you have clearly expressed complete requirements but the system explicitly states it cannot complete them due to technical limitations - in this case, accept transfer to human.",(0,s.jsx)("br",{}),"# How to finish the conversation:",(0,s.jsx)("br",{}),"- If the agent has completed all tasks, generate '###STOP###' as a standalone message without anything else to end the conversation.",(0,s.jsx)("br",{}),"# Note:",(0,s.jsx)("br",{}),"- You should carefully check if the agent has completed all tasks mentioned in the instruction before generating '###STOP###'.",(0,s.jsx)("br",{}),'"""']})]}):"zh"===t?(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"我们正式介绍两个新的 GLM 系列成员：GLM-4.5 和 GLM-4.5-Air——我们最新的旗舰模型。GLM-4.5 拥有 3550 亿总参数和 320 亿激活参数，而 GLM-4.5-Air 拥有 1060 亿总参数和 120 亿激活参数。两者都旨在将推理、编程和智能体能力统一到一个模型中，以满足快速增长的智能体应用日益复杂的需求。"}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["GLM-4.5 和 GLM-4.5-Air 都是混合推理模型，提供：用于复杂推理和工具使用的",(0,s.jsx)("em",{children:"思考"}),"模式，以及用于即时响应的",(0,s.jsx)("em",{children:"非思考"}),"模式。它们可在"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"}),"、智谱清言（",(0,s.jsx)("a",{href:"https://chatglm.cn",target:"_blank",className:"hover:text-gray-500 underline",children:"chatglm.cn"}),"）和开放平台"," ",(0,s.jsx)("a",{href:"https://bigmodel.cn",target:"_blank",className:"hover:text-gray-500 underline",children:"BigModel"})," ","上使用，开放权重可在"," ",(0,s.jsx)("a",{href:"https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b",target:"_blank",className:"hover:text-gray-500 underline",children:"HuggingFace"})," ","和"," ",(0,s.jsx)("a",{href:"https://modelscope.cn/collections/GLM-45-b8693e2a08984f",target:"_blank",className:"hover:text-gray-500 underline",children:"ModelScope"})," ","获取。欢迎开发者、企业、用户广泛测试与集成，探索 AGI 的奥秘。"]}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:[(0,s.jsx)("strong",{children:"背景："})," ","大语言模型的目标是在广泛领域达到人类认知水平，而非针对特定任务而设计专家模型。一个优秀的大语言模型必须具备通用问题解决、泛化能力、常识推理和自我改进等核心能力。过去五年里，OpenAI 的 GPT-3 学会了常识知识，而 o1 模型则通过强化学习实现了“先思考后回答”，在编程、数据分析和复杂数学问题上的推理能力得到了显著提升。然而，现有模型仍然算不上真正的通用模型：有些擅长编程，有些精于数学，有些在推理方面表现出色，但没有一个能在所有任务上都达到最佳表现。GLM-4.5 正是朝着统一各种能力这一目标努力，力求在一个模型中集成所有这些不同的能力。"]}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"总体性能"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"我们在涵盖智能体（3 项）、推理（7 项）和编程（2 项）的 12 个基准测试上将 GLM-4.5 与来自 OpenAI、Anthropic、Google DeepMind、xAI、阿里巴巴、月之暗面和深度求索的各种模型进行了比较。总体而言，GLM-4.5 排名第 3，GLM-4.5 Air 排名第 6。"})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/20250729-141203.png",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"智能体任务"})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"GLM-4.5 是一个为智能体任务优化的基础模型。它提供 128k 的上下文长度和原生函数调用能力。我们在 τ-bench 和 BFCL-v3（Berkeley Function Calling Leaderboard v3）上测量了其智能体能力。在这两个基准测试上，GLM-4.5 与 Claude 4 Sonnet 的性能相匹配。"})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/HJ4VZkBDxe.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsx)("div",{className:"flex flex-col items-center gap-4 pt-2",children:(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["网页浏览是一个流行的智能体应用，需要复杂的推理和多轮工具使用。我们在"," ",(0,s.jsx)("a",{href:"https://openai.com/index/browsecomp",target:"_blank",className:"hover:text-gray-500 underline",children:"BrowseComp"})," ","基准测试上评估了 GLM-4.5，这是一个具有挑战性的网页浏览基准测试，包含需要简短回答的复杂问题。借助网页浏览工具，GLM-4.5 对 26.4% 的问题给出了正确回答，明显优于 Claude-4-Opus（18.8%），接近 o4-mini-high（28.3%）。下图显示了 GLM-4.5 在 BrowseComp 上随测试时间扩展的准确性提升。"]})}),(0,s.jsx)("div",{className:"p-5 flex flex-col items-center max-w-[60rem]",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/HyiDl_Ewge.jpg",className:"rounded-lg bg-cover bg-center bg-no-repeat",style:{width:"50%"}})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("div",{style:{maxWidth:"min(60rem, 100vw)",overflowY:"scroll"},children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"基准测试"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5-Air"}),(0,s.jsx)("th",{children:"o3"}),(0,s.jsx)("th",{children:"o4-mini-high"}),(0,s.jsx)("th",{children:"GPT-4.1"}),(0,s.jsx)("th",{children:"Claude 4 Opus"}),(0,s.jsx)("th",{children:"Claude 4 Sonnet"}),(0,s.jsx)("th",{children:"Gemini 2.5 Pro"}),(0,s.jsx)("th",{children:"Qwen3 235B Thinking 2507"}),(0,s.jsx)("th",{children:"DeepSeek-R1-0528"}),(0,s.jsx)("th",{children:"DeepSeek V3 0324"}),(0,s.jsx)("th",{children:"Kimi K2"}),(0,s.jsx)("th",{children:"Grok 4"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"TAU-bench-Retail"}),(0,s.jsx)("td",{className:"highlight",children:"79.7"}),(0,s.jsx)("td",{className:"highlight",children:"77.9"}),(0,s.jsx)("td",{children:"70.4"}),(0,s.jsx)("td",{children:"65.6"}),(0,s.jsx)("td",{children:"75.1"}),(0,s.jsx)("td",{children:"81.4"}),(0,s.jsx)("td",{children:"80.5"}),(0,s.jsx)("td",{children:"77.0"}),(0,s.jsx)("td",{children:"71.9"}),(0,s.jsx)("td",{children:"63.9"}),(0,s.jsx)("td",{children:"74.7"}),(0,s.jsx)("td",{children:"73.9"}),(0,s.jsx)("td",{children:"76.5"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"TAU-bench-Airline"}),(0,s.jsx)("td",{className:"highlight",children:"60.4"}),(0,s.jsx)("td",{className:"highlight",children:"60.8"}),(0,s.jsx)("td",{children:"52.0"}),(0,s.jsx)("td",{children:"49.2"}),(0,s.jsx)("td",{children:"48.8"}),(0,s.jsx)("td",{children:"59.6"}),(0,s.jsx)("td",{children:"60.0"}),(0,s.jsx)("td",{children:"48.0"}),(0,s.jsx)("td",{children:"58.0"}),(0,s.jsx)("td",{children:"53.5"}),(0,s.jsx)("td",{children:"40.4"}),(0,s.jsx)("td",{children:"51.2"}),(0,s.jsx)("td",{children:"58.4"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"BFCL v3 (完整版)"}),(0,s.jsx)("td",{className:"highlight",children:"77.8"}),(0,s.jsx)("td",{className:"highlight",children:"76.4"}),(0,s.jsx)("td",{children:"72.4"}),(0,s.jsx)("td",{children:"67.2"}),(0,s.jsx)("td",{children:"68.9"}),(0,s.jsx)("td",{children:"74.4"}),(0,s.jsx)("td",{children:"75.2"}),(0,s.jsx)("td",{children:"61.2"}),(0,s.jsx)("td",{children:"71.9"}),(0,s.jsx)("td",{children:"63.8"}),(0,s.jsx)("td",{children:"64.7"}),(0,s.jsx)("td",{children:"71.1"}),(0,s.jsx)("td",{children:"66.2"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"BrowseComp"}),(0,s.jsx)("td",{className:"highlight",children:"26.4"}),(0,s.jsx)("td",{className:"highlight",children:"21.3"}),(0,s.jsx)("td",{children:"49.7"}),(0,s.jsx)("td",{children:"28.3"}),(0,s.jsx)("td",{children:"4.1"}),(0,s.jsx)("td",{children:"18.8"}),(0,s.jsx)("td",{children:"14.7"}),(0,s.jsx)("td",{children:"7.6"}),(0,s.jsx)("td",{children:"4.6"}),(0,s.jsx)("td",{children:"3.2"}),(0,s.jsx)("td",{children:"1.5"}),(0,s.jsx)("td",{children:"7.9"}),(0,s.jsx)("td",{children:"32.6"})]})]})]})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"推理"})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"在思考模式下，GLM-4.5 和 GLM-4.5-Air 可以解决复杂的推理问题，包括数学、科学和逻辑问题。"}),(0,s.jsx)("div",{style:{maxWidth:"min(60rem, 100vw)",overflowY:"scroll"},children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"基准测试"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5-Air"}),(0,s.jsx)("th",{children:"o3"}),(0,s.jsx)("th",{children:"Claude 4 Opus"}),(0,s.jsx)("th",{children:"Gemini 2.5 Pro"}),(0,s.jsx)("th",{children:"DeepSeek-R1-0528"}),(0,s.jsx)("th",{children:"Qwen3-235B-Thinking 2507"}),(0,s.jsx)("th",{children:"Grok 4"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"MMLU Pro"}),(0,s.jsx)("td",{className:"highlight",children:"84.6"}),(0,s.jsx)("td",{className:"highlight",children:"81.4"}),(0,s.jsx)("td",{children:"85.3"}),(0,s.jsx)("td",{children:"87.3"}),(0,s.jsx)("td",{children:"86.2"}),(0,s.jsx)("td",{children:"84.9"}),(0,s.jsx)("td",{children:"84.5"}),(0,s.jsx)("td",{children:"86.6"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"AIME 24"}),(0,s.jsx)("td",{className:"highlight",children:"91.0"}),(0,s.jsx)("td",{className:"highlight",children:"89.4"}),(0,s.jsx)("td",{children:"90.3"}),(0,s.jsx)("td",{children:"75.7"}),(0,s.jsx)("td",{children:"88.7"}),(0,s.jsx)("td",{children:"89.3"}),(0,s.jsx)("td",{children:"94.1"}),(0,s.jsx)("td",{children:"94.3"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"MATH 500"}),(0,s.jsx)("td",{className:"highlight",children:"98.2"}),(0,s.jsx)("td",{className:"highlight",children:"98.1"}),(0,s.jsx)("td",{children:"99.2"}),(0,s.jsx)("td",{children:"98.2"}),(0,s.jsx)("td",{children:"96.7"}),(0,s.jsx)("td",{children:"98.3"}),(0,s.jsx)("td",{children:"98.0"}),(0,s.jsx)("td",{children:"99.0"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"SciCode"}),(0,s.jsx)("td",{className:"highlight",children:"41.7"}),(0,s.jsx)("td",{className:"highlight",children:"37.3"}),(0,s.jsx)("td",{children:"41.0"}),(0,s.jsx)("td",{children:"39.8"}),(0,s.jsx)("td",{children:"42.8"}),(0,s.jsx)("td",{children:"40.3"}),(0,s.jsx)("td",{children:"42.9"}),(0,s.jsx)("td",{children:"45.7"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"GPQA"}),(0,s.jsx)("td",{className:"highlight",children:"79.1"}),(0,s.jsx)("td",{className:"highlight",children:"75.0"}),(0,s.jsx)("td",{children:"82.7"}),(0,s.jsx)("td",{children:"79.6"}),(0,s.jsx)("td",{children:"84.4"}),(0,s.jsx)("td",{children:"81.3"}),(0,s.jsx)("td",{children:"81.1"}),(0,s.jsx)("td",{children:"87.7"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"HLE"}),(0,s.jsx)("td",{className:"highlight",children:"14.4"}),(0,s.jsx)("td",{className:"highlight",children:"10.6"}),(0,s.jsx)("td",{children:"20.0"}),(0,s.jsx)("td",{children:"11.7"}),(0,s.jsx)("td",{children:"21.1"}),(0,s.jsx)("td",{children:"14.9"}),(0,s.jsx)("td",{children:"15.8"}),(0,s.jsx)("td",{children:"23.9"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"LCB (2407-2501)"}),(0,s.jsx)("td",{className:"highlight",children:"72.9"}),(0,s.jsx)("td",{className:"highlight",children:"70.7"}),(0,s.jsx)("td",{children:"78.4"}),(0,s.jsx)("td",{children:"63.6"}),(0,s.jsx)("td",{children:"80.1"}),(0,s.jsx)("td",{children:"77.0"}),(0,s.jsx)("td",{children:"78.2"}),(0,s.jsx)("td",{children:"81.9"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsx)("td",{children:"AA-Index (估计)"}),(0,s.jsx)("td",{className:"highlight",children:"67.7"}),(0,s.jsx)("td",{className:"highlight",children:"64.8"}),(0,s.jsx)("td",{children:"70.0"}),(0,s.jsx)("td",{children:"64.4"}),(0,s.jsx)("td",{children:"70.5"}),(0,s.jsx)("td",{children:"68.3"}),(0,s.jsx)("td",{children:"69.4"}),(0,s.jsx)("td",{children:"73.2"})]})]})]})}),(0,s.jsx)("blockquote",{className:"max-w-[60rem] self-stretch font-poppins text-base font-normal leading-7 border-l-4 border-gray-400 pl-4 italic text-gray-600",children:(0,s.jsx)("p",{children:"对于 AIME 和 GPQA 基准测试，我们分别报告了 32 个和 8 个样本的平均准确率（Avg@32，Avg@8）以减轻结果方差。使用 LLM 进行自动答案验证。对于 HLE 基准测试，仅评估了基于文本的问题，正确性由 GPT-4o 判断。"})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"编程"})}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"GLM-4.5 擅长编程，包括从头开始构建编程项目和在现有项目中作为智能体解决编程任务。"}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["它可以与现有的编程工具无缝结合，如"," ",(0,s.jsx)("a",{href:"https://github.com/anthropics/claude-code",target:"_blank",className:"hover:text-gray-500 underline",children:"Claude Code"}),"、",(0,s.jsx)("a",{href:"https://github.com/RooCodeInc/Roo-Code",target:"_blank",className:"hover:text-gray-500 underline",children:"Roo Code"})," ","和"," ",(0,s.jsx)("a",{href:"https://codegeex.cn/",target:"_blank",className:"hover:text-gray-500 underline",children:"CodeGeex"}),"。为了评估编程能力，我们在 SWE-bench Verified 和 Terminal-Bench 上比较了不同模型。下表展示了结果。"]}),(0,s.jsx)("div",{style:{maxWidth:"min(60rem, 100vw)",overflowY:"scroll"},children:(0,s.jsxs)("table",{children:[(0,s.jsx)("thead",{children:(0,s.jsxs)("tr",{children:[(0,s.jsx)("th",{children:"基准测试"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5"}),(0,s.jsx)("th",{className:"highlight",children:"GLM-4.5-Air"}),(0,s.jsx)("th",{children:"o3"}),(0,s.jsx)("th",{children:"GPT-4.1"}),(0,s.jsx)("th",{children:"Claude 4 Opus"}),(0,s.jsx)("th",{children:"Claude 4 Sonnet"}),(0,s.jsx)("th",{children:"Gemini 2.5 Pro"}),(0,s.jsx)("th",{children:"DeepSeek-R1-0528"}),(0,s.jsx)("th",{children:"Kimi K2"})]})}),(0,s.jsxs)("tbody",{children:[(0,s.jsxs)("tr",{children:[(0,s.jsxs)("td",{children:["SWE-bench Verified",(0,s.jsx)("sup",{children:"1"})]}),(0,s.jsx)("td",{className:"highlight",children:"64.2"}),(0,s.jsx)("td",{className:"highlight",children:"57.6"}),(0,s.jsx)("td",{children:"69.1"}),(0,s.jsx)("td",{children:"48.6"}),(0,s.jsx)("td",{children:"67.8"}),(0,s.jsx)("td",{children:"70.4"}),(0,s.jsx)("td",{children:"49.0"}),(0,s.jsx)("td",{children:"41.4"}),(0,s.jsx)("td",{children:"65.4"})]}),(0,s.jsxs)("tr",{children:[(0,s.jsxs)("td",{children:["Terminal-Bench",(0,s.jsx)("sup",{children:"2"})]}),(0,s.jsx)("td",{className:"highlight",children:"37.5"}),(0,s.jsx)("td",{className:"highlight",children:"30"}),(0,s.jsx)("td",{children:"30.2"}),(0,s.jsx)("td",{children:"30.3"}),(0,s.jsx)("td",{children:"43.2"}),(0,s.jsx)("td",{children:"35.5"}),(0,s.jsx)("td",{children:"25.3"}),(0,s.jsx)("td",{children:"17.5"}),(0,s.jsx)("td",{children:"25.0"})]})]})]})}),(0,s.jsxs)("blockquote",{className:"max-w-[60rem] self-stretch font-poppins text-base font-normal leading-7 border-l-4 border-gray-400 pl-4 italic text-gray-600",children:[(0,s.jsxs)("p",{children:[(0,s.jsx)("sup",{children:"1"})," 对于 SWE-bench Verified，我们使用 OpenHands v0.34.0，运行限制为 100 次迭代，并截断历史记录以防止超过 128K 上下文限制，配置为 temperature=0.6，top_p=1.0。"]}),(0,s.jsxs)("p",{children:[(0,s.jsx)("sup",{children:"2"})," 对于 Terminal-Bench，我们使用 Terminus 框架进行评估。我们使用标准函数调用而不是直接提示进行评估。"]})]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"我们对所有比较模型进行了帕累托前沿分析（如下图所示）。GLM-4.5 和 GLM-4.5-Air 相对于相似规模的模型表现出优越的性能，在性能-参数量权衡上实现了最佳效率。"})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/S1tGskrPge.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsx)("div",{className:"flex flex-col items-center gap-4 pt-2",children:(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"为了评估 GLM-4.5 的智能体编程能力，我们使用 Claude Code 作为评测工具，将其与 Claude 4 Sonnet、Kimi K2 和 Qwen3-Coder 进行对比。测试涵盖了 52 个编程任务，包括前端开发、工具开发、数据分析、测试和算法实现等多个领域。所有评测都在独立的 Docker 容器中进行，并通过多轮人机交互并采用标准化的评估准则确保测试的一致性和可重复性。实验结果显示，GLM-4.5 对 Kimi K2 的胜率达到 53.9%，对 Qwen3-Coder 更是取得了 80.8% 的压倒性优势。尽管 GLM-4.5 展现出了不错的竞争力，但与 Claude-4-Sonnet 相比，仍有进一步优化的空间。"})}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/ByZG-kBvgg.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsx)("div",{className:"flex flex-col items-center gap-4 pt-2",children:(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["值得注意的是，GLM-4.5 的平均工具调用成功率最高（90.6%），优于 Claude-4-Sonnet（89.5%）、Kimi-K2（86.2%）和 Qwen3-Coder（77.1%），展示了在智能体编程任务中的可靠性。所有 52 个编程任务的轨迹公开在",(0,s.jsx)("a",{href:"https://huggingface.co/datasets/zai-org/CC-Bench-trajectories",target:"_blank",className:"hover:text-gray-500 underline",children:"此处"}),"供社区进一步研究。链接：",(0,s.jsx)("a",{href:"https://huggingface.co/datasets/zai-org/CC-Bench-trajectories",target:"_blank",className:"hover:text-gray-500 underline",children:"https://huggingface.co/datasets/zai-org/CC-Bench-trajectories"})]})}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/H1jQbyHvlx.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"技术"}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"模型架构和预训练"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:'在 GLM-4.5 系列模型中，我们采用了 MoE（专家混合）架构，这种架构能够显著提升训练和推理时的计算效率。我们在 MoE 层采用了 loss-free balance 路由和 sigmoid gate 机制。与 DeepSeek-V3 和 Kimi K2 的设计思路不同，我们选择了"瘦高"的模型结构——减少模型的宽度（包括隐藏维度和路由专家的数量），同时增加模型的深度（层数）。我们发现，更深的模型在推理能力上表现更加出色。在自注意力机制方面，我们采用了 partal RoPE 的分组查询注意力（Grouped-Query Attention）。另外，我们将注意力头的数量增加到了 2.5 倍（在 5120 的隐藏维度下使用 96 个注意力头）。有意思的是，虽然增加注意力头的数量并没有让训练 loss 更低，但在 MMLU 和 BBH 等推理基准测试中，模型的表现却得到了稳定提升。GLM-4.5 使用了 Muon 优化器，这个优化器不仅能加快模型收敛速度，还能在更大的 Batch Size 下相比 AdamW 保持更好的收敛效果，从而提升训练效率。我们还引入了 QK-Norm 技术来提升注意力 logits 的数值稳定性。GLM-4.5 和 GLM-4.5-Air 都加入了 MTP（Multi Token Predition）层，用于在推理阶段实现推测解码，进一步提升推理效率。'})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/SyDLepVveg.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"我们的基础模型经历了几个训练阶段。在预训练期间，模型首先在 15T token 的通用预训练语料库上训练，然后在 7T token 的代码和推理语料库上训练。预训练后，我们引入了 Mid-Training 阶段来进一步提升模型在专有领域上的性能。"}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"基于 slime 的大模型强化学习"})]}),(0,s.jsx)("div",{className:"p-5",children:(0,s.jsx)("img",{src:"https://z-cdn.chatglm.cn/z-blog/B1pJ-JSvxx.jpg",className:"w-[60rem] rounded-lg bg-cover bg-center bg-no-repeat"})}),(0,s.jsxs)("div",{className:"flex flex-col items-center gap-4 pt-2",children:[(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["为了支持 GLM-4.5 这样的大模型进行高效的强化学习（RL）训练，我们设计、开发并开源了"," ",(0,s.jsx)("a",{href:"https://github.com/THUDM/slime",target:"_blank",className:"hover:text-gray-500 underline",children:(0,s.jsx)("strong",{children:"slime"})}),"。这是一个在灵活性、效率和可扩展性方面都表现卓越的 RL 框架，欢迎社区使用并参与贡献。"]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"slime 旨在解决强化学习中的常见瓶颈，并针对复杂的智能体任务做了优化"}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["• ",(0,s.jsx)("strong",{children:"灵活的混合训练架构："})," slime 的核心优势在于其多功能的混合架构。它既支持同步、集中式训练（适合推理和通用强化学习训练），也支持分布式、异步训练模式。这种异步模式对于 Agentic RL 至关重要，因为在这类场景中，数据生成往往是一个缓慢的外部过程。通过将训练与数据收集解耦，我们可以确保训练 GPU 始终保持满负荷运行，最大化硬件利用率。",(0,s.jsx)("br",{})," • ",(0,s.jsx)("strong",{children:"面向智能体的解耦设计："})," Agentic RL 经常面临环境交互时延迟高且分布长尾的问题，这严重限制了训练吞吐量。为此，slime 实现了完全解耦的基础架构，将环境交互引擎与训练引擎分离。这两个组件在不同的硬件上独立运行，将数据生成的瓶颈转化为可并行化的非阻塞过程。这种设计是加速长序列智能体任务的关键。",(0,s.jsx)("br",{})," • ",(0,s.jsx)("strong",{children:"混合精度加速数据生成："})," ","为了进一步提升吞吐量，slime 采用混合精度推理来加速环境交互。它使用 FP8 格式进行数据生成（Rollout），同时在模型训练中保留 BF16 以确保训练稳定性。这种技术在不影响训练质量的前提下，大幅提升了数据生成速度。"]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"这种整体化的设计使得 slime 能够无缝集成多个智能体框架，支持各种任务类型，并通过统一而强大的接口高效管理长序列环境交互。"}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"增强智能体能力的后训练"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"后训练对大语言模型至关重要，模型通过自主探索和积累经验来不断优化策略。强化学习（RL）是突破模型能力边界的关键步骤。GLM-4.5 不仅整合了 GLM-4-0414 的通用能力和 GLM-Z1 的推理能力，还重点提升了智能体能力，包括智能体编程、深度搜索和通用工具使用。"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"训练过程首先在精选的推理数据和合成的智能体场景上进行监督微调，然后通过专门的强化学习阶段分别训练专家模型。"}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["• ",(0,s.jsx)("strong",{children:"推理能力训练："})," 我们在完整的 64K 上下文长度上进行单阶段强化学习，采用基于难度的课程学习来进行多阶段 RL。为了确保训练稳定性，我们引入了改进的技术：使用动态采样温度来平衡探索与利用，以及在 STEM 问题上使用自适应裁剪来保证策略更新的稳定性。",(0,s.jsx)("br",{})," • ",(0,s.jsx)("strong",{children:"智能体任务训练："})," ","训练聚焦于两个可验证的任务：基于信息检索的问答和软件工程任务。我们开发了可扩展的策略来合成基于搜索的问答对，方法是通过人工参与的内容提取和选择性地模糊网页内容。编程任务则通过在真实软件工程任务上基于执行结果的反馈来驱动。"]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"虽然强化学习训练只针对有限的可验证任务，但获得的能力提升可以迁移到相关领域，比如通用工具使用能力。最后，我们通过专家蒸馏将这些专门技能整合起来，使 GLM-4.5 在各项任务上都具备全面的能力。"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"更多技术细节，请参考即将发布的 GLM-4.5 技术报告。"}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"演示"}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"Artifacts"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"GLM-4.5 增强了 GLM-4-0414 的复杂代码生成能力。GLM-4.5 可以创建复杂的 Artifacts，包括小游戏、小工具、物理模拟动画等，支持 HTML、SVG、Python 等多种语言。我们相信 GLM-4.5 的 Artifacts 将提供更好的用户体验，同时为 Agentic Coding 应用奠定了基础。"}),(0,s.jsx)(c,{language:t}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"幻灯片创建"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"在 GLM-4.5 工具使用和 HTML 编码能力的基础上，我们开发了一个模型原生的 PPT / Poster 智能体。无论用户需要简单还是复杂的设计，或是上传文档资料， GLM-4.5 Agent 都能自动搜索网络资源、获取相关图片，并生成相应的幻灯片。"}),(0,s.jsx)(o,{language:t}),(0,s.jsx)("h2",{className:"max-w-[60rem] pb-2 self-stretch font-poppins text-grey-9 text-2xl font-bold leading-[125%]",children:"全栈开发"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:"GLM-4.5 在前后端开发上游刃有余，是构建现代 Web 应用的利器。为了充分展现这一能力，我们借鉴 Claude Code 框架打造了一款编码智能体。基于预置的全栈网站框架，用户可以一句话生成完整网站，并通过多轮对话轻松添加新功能、完善项目细节。"}),(0,s.jsx)(x,{language:t}),(0,s.jsx)("h1",{className:"max-w-[60rem] py-3 self-stretch font-poppins text-grey-9 text-3xl font-bold leading-[125%]",children:"开始使用 GLM-4.5"}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsxs)("strong",{children:["在"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"})," ","上与 GLM-4.5 聊天"]})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["GLM-4.5 可通过"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"})," ","平台访问，方法是选择 GLM-4.5 模型选项。该平台全面支持前端产物生成、演示幻灯片创建和全栈开发能力。"]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsxs)("strong",{children:["在"," ",(0,s.jsx)("a",{href:"https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5",target:"_blank",className:"hover:text-gray-500 underline",children:"BigModel.cn"})," ","上调用 GLM-4.5 API"]})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:[(0,s.jsx)("a",{href:"https://bigmodel.cn/",target:"_blank",className:"hover:text-gray-500 underline",children:"BigModel API 平台"})," ","为 GLM-4.5 和 GLM-4.5-Air 模型提供 OpenAI 兼容的接口。有关全面的 API 文档和集成指南，请参考"," ",(0,s.jsx)("a",{href:"https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5。",target:"_blank",className:"hover:text-gray-500 underline",children:"https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5"}),"。"]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"将 GLM-4.5 与编码代理一起使用"})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["有关将 GLM-4.5 与 Claude Code 和其他编码代理框架集成的详细说明，请参阅"," ",(0,s.jsx)("a",{href:"https://docs.bigmodel.cn/cn/guide/develop/claude",target:"_blank",className:"hover:text-gray-500 underline",children:"BigModel.cn"})," ","上的文档。"]}),(0,s.jsx)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:(0,s.jsx)("strong",{children:"本地部署 GLM-4.5"})}),(0,s.jsxs)("p",{className:"max-w-[60rem] self-stretch font-poppins text-grey-8 text-base font-normal leading-7",children:["GLM-4.5 和 GLM-4.5-Air 的基础和聊天变体的模型权重在"," ",(0,s.jsx)("a",{href:"https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b",target:"_blank",className:"hover:text-gray-500 underline",children:"HuggingFace"})," ","和"," ",(0,s.jsx)("a",{href:"https://modelscope.cn/collections/GLM-45-b8693e2a08984f",target:"_blank",className:"hover:text-gray-500 underline",children:"ModelScope"})," ","上公开可用。对于本地部署，GLM-4.5 支持包括 vLLM 和 SGLang 在内的推理框架。全面的部署说明，详见官方"," ",(0,s.jsx)("a",{href:"https://github.com/zai-org/GLM-4.5",target:"_blank",className:"hover:text-gray-500 underline",children:"GitHub 仓库"}),"。"]})]})]}):void 0}function g(){let[e,t]=(0,i.useState)("en"),{title:n,subtitle:a,tryZai:l,callZai:c,zaiDocument:d,legal:o,privacyPolicy:h,termsOfService:x}="en"===e?{title:"GLM-4.5: Reasoning, Coding, and Agentic Abililties",subtitle:"Our latest frontier model series, excels in reasoning, coding and agentic tasks.",tryZai:"Try it at Z.ai",callZai:"Call it at Z.ai",zaiDocument:"https://docs.z.ai/guides/llm/glm-4.5",legal:"Legal",privacyPolicy:"Privacy Policy",termsOfService:"Terms of Service"}:{title:"GLM-4.5：原生融合推理、编码和智能体能力",subtitle:"我们最新的前沿模型系列，在推理、编码和智能体任务方面表现出色。",tryZai:"在 Z.ai 上尝试",callZai:"通过 Z.ai API 调用",zaiDocument:"https://docs.bigmodel.cn/cn/guide/models/text/glm-4.5",legal:"法律信息",privacyPolicy:"隐私政策",termsOfService:"使用协议"};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)("title",{children:n}),(0,s.jsxs)("div",{className:"bg-background no-scrollbar 4xl:px-0 relative mx-auto flex min-h-screen max-w-[1440px] flex-col items-center",children:[(0,s.jsxs)("div",{className:"flex flex-col items-center justify-center w-full px-[1.5rem]",children:[(0,s.jsxs)("div",{className:"flex pt-20 px-5 pb-10 flex-col justify-center items-center gap-6 self-stretch",style:{fontFamily:"Poppins, Poppins Fallback"},children:[(0,s.jsx)("div",{className:"text-grey-5 font-poppins text-base font-normal leading-[125%]",children:"2025-07-28 \xb7 Research"}),(0,s.jsx)("h1",{className:"max-w-[60rem] text-grey-9 text-center font-poppins text-5xl font-medium leading-[125%] m-0",children:n}),(0,s.jsx)("p",{className:"max-w-[60rem] text-grey-6 text-center font-poppins text-base font-normal leading-[125%] m-0",children:a}),(0,s.jsxs)("div",{className:"flex flex-wrap items-center",children:[(0,s.jsx)("a",{href:"https://z.ai",target:"_blank",children:(0,s.jsxs)("li",{className:"3xl:text-base hover:bg-card-background group flex cursor-pointer list-none items-center justify-between rounded-lg px-3 text-sm leading-7.5 font-medium gap-2",children:[(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/z-icon.svg",alt:"",height:28,width:28}),(0,s.jsx)("span",{children:l}),(0,s.jsx)("svg",{width:"16",height:"16",viewBox:"0 0 16 16",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"text-grey-5",children:(0,s.jsx)("path",{d:"M4 4H12M12 12V4M12 4L4 12",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round"})})]})}),(0,s.jsx)("a",{href:d,target:"_blank",children:(0,s.jsxs)("li",{className:"3xl:text-base hover:bg-card-background group flex cursor-pointer list-none items-center justify-between rounded-lg px-3 text-sm leading-7.5 font-medium gap-2",children:[(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/z-icon.svg",alt:"",height:28,width:28}),(0,s.jsx)("span",{children:c}),(0,s.jsx)("svg",{width:"16",height:"16",viewBox:"0 0 16 16",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"text-grey-5",children:(0,s.jsx)("path",{d:"M4 4H12M12 12V4M12 4L4 12",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round"})})]})}),(0,s.jsx)("a",{href:"https://github.com/zai-org/GLM-4.5",target:"_blank",children:(0,s.jsxs)("li",{className:"3xl:text-base hover:bg-card-background group flex cursor-pointer list-none items-center justify-between rounded-lg px-3 text-sm leading-7.5 font-medium gap-2",children:[(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/github-mark.svg",alt:"",height:27,width:27}),(0,s.jsx)("span",{children:"GitHub"}),(0,s.jsx)("svg",{width:"16",height:"16",viewBox:"0 0 16 16",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"text-grey-5",children:(0,s.jsx)("path",{d:"M4 4H12M12 12V4M12 4L4 12",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round"})})]})}),(0,s.jsx)("a",{href:"https://huggingface.co/collections/zai-org/glm-45-687c621d34bda8c9e4bf503b",target:"_blank",children:(0,s.jsxs)("li",{className:"3xl:text-base hover:bg-card-background group flex cursor-pointer list-none items-center justify-between rounded-lg px-3 text-sm leading-7.5 font-medium gap-2",children:[(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/hf-logo.svg",alt:"",height:35,width:35}),(0,s.jsx)("span",{children:"HuggingFace"}),(0,s.jsx)("svg",{width:"16",height:"16",viewBox:"0 0 16 16",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"text-grey-5",children:(0,s.jsx)("path",{d:"M4 4H12M12 12V4M12 4L4 12",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round"})})]})}),(0,s.jsx)("a",{href:"https://arxiv.org/abs/2508.06471",target:"_blank",children:(0,s.jsxs)("li",{className:"3xl:text-base hover:bg-card-background group flex cursor-pointer list-none items-center justify-between rounded-lg px-3 text-sm leading-7.5 font-medium gap-2",children:[(0,s.jsx)("span",{style:{fontSize:24},children:"\uD83D\uDCC4"}),(0,s.jsx)("span",{children:"Tech Report"}),(0,s.jsx)("svg",{width:"16",height:"16",viewBox:"0 0 16 16",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"text-grey-5",children:(0,s.jsx)("path",{d:"M4 4H12M12 12V4M12 4L4 12",stroke:"currentColor",strokeWidth:"2",strokeLinecap:"round"})})]})})]})]}),(0,s.jsx)(m,{language:e})]}),(0,s.jsxs)("footer",{className:"w-full pt-10",children:[(0,s.jsx)("div",{className:"border-grey-3 w-full border-t"}),(0,s.jsxs)("div",{className:"flex justify-between p-10 max-md:flex-col max-md:gap-10 max-md:px-5",children:[(0,s.jsx)(r.default,{src:"https://z-cdn.chatglm.cn/z-blog/z-icon.svg",alt:"",width:130,height:130}),(0,s.jsx)("div",{className:"flex flex-wrap gap-10",children:(0,s.jsxs)("div",{className:"text-grey-8 3xl:text-base flex min-w-20 flex-col gap-6 text-sm leading-[125%] font-medium",children:[(0,s.jsx)("h3",{className:"text-grey-5",children:o}),(0,s.jsx)("a",{href:"https://chat.z.ai/legal-agreement/privacy-policy",target:"_blank",children:h}),(0,s.jsx)("a",{href:"https://chat.z.ai/legal-agreement/terms-of-service",target:"_blank",children:x})]})})]}),(0,s.jsx)("div",{className:"border-grey-3 w-full border-t"}),(0,s.jsxs)("div",{className:"mb-10 flex items-center justify-between px-10 pt-5 max-md:px-5",children:[(0,s.jsxs)("span",{className:"text-text-secondary",children:["\xa9 2025"," ",(0,s.jsx)("a",{href:"https://chat.z.ai",target:"_blank",className:"hover:text-gray-500 underline",children:"Z.ai"})," ","Inc."]}),(0,s.jsxs)("div",{className:"flex gap-4",children:[(0,s.jsx)("a",{href:"https://x.com/zai_org",target:"_blank",children:(0,s.jsxs)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"text-text-secondary hover:text-black",children:[(0,s.jsx)("mask",{id:"mask0_73_2327","mask-type":"luminance",maskUnits:"userSpaceOnUse",x:"5",y:"5",width:"14",height:"14",children:(0,s.jsx)("path",{d:"M5 5H19V19H5V5Z",fill:"white"})}),(0,s.jsx)("g",{mask:"url(#mask0_73_2327)",children:(0,s.jsx)("path",{d:"M16.025 5.65601H18.172L13.482 11.03L19 18.344H14.68L11.294 13.909L7.424 18.344H5.275L10.291 12.594L5 5.65701H9.43L12.486 9.71001L16.025 5.65601ZM15.27 17.056H16.46L8.78 6.87701H7.504L15.27 17.056Z",fill:"currentColor"})})]})}),(0,s.jsx)("a",{href:"https://github.com/THUDM",target:"_blank",children:(0,s.jsx)("svg",{width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",xmlns:"http://www.w3.org/2000/svg",className:"text-text-secondary hover:text-black",children:(0,s.jsx)("path",{d:"M9.34978 16.8799C9.34978 16.9499 9.27978 16.9999 9.17978 16.9999C9.07978 16.9999 8.99978 16.9999 8.99978 16.8799C8.99978 16.7599 9.07978 16.7599 9.16978 16.7599C9.25978 16.7599 9.34978 16.8099 9.34978 16.8799ZM8.34978 16.7299C8.34978 16.7999 8.34978 16.8799 8.48978 16.8999C8.52559 16.9171 8.56676 16.9194 8.60426 16.9063C8.64175 16.8931 8.67251 16.8657 8.68978 16.8299C8.68978 16.7599 8.68978 16.6899 8.54978 16.6599C8.40978 16.6299 8.36978 16.6599 8.34978 16.7299ZM9.76978 16.6799C9.67978 16.6799 9.61978 16.7599 9.62978 16.8399C9.63978 16.9199 9.71978 16.9499 9.81978 16.9299C9.91978 16.9099 9.96978 16.8399 9.95978 16.7699C9.94978 16.6999 9.86978 16.6699 9.76978 16.6799ZM11.8998 3.9999C10.8451 3.98997 9.79937 4.19321 8.82522 4.59742C7.85107 5.00163 6.96862 5.59848 6.23083 6.35215C5.49303 7.10582 4.91511 8.00078 4.53172 8.98331C4.14834 9.96585 3.96741 11.0157 3.99978 12.0699C3.97187 13.7968 4.48401 15.4893 5.46468 16.911C6.44535 18.3327 7.84558 19.4126 9.46978 19.9999C9.87978 20.0699 10.0298 19.8099 10.0298 19.5999V17.5999C10.0298 17.5999 7.76978 18.0999 7.28978 16.5999C7.28978 16.5999 6.92978 15.5999 6.39978 15.3899C6.39978 15.3899 5.65978 14.8699 6.44978 14.8799C6.70853 14.9148 6.95549 15.0099 7.17084 15.1575C7.38619 15.3051 7.56393 15.5011 7.68978 15.7299C7.79442 15.935 7.93985 16.1165 8.11717 16.2634C8.29449 16.4103 8.49995 16.5194 8.72094 16.584C8.94193 16.6486 9.1738 16.6674 9.4023 16.6392C9.63081 16.6109 9.85115 16.5363 10.0498 16.4199C10.0876 16.0024 10.2677 15.6106 10.5598 15.3099C8.75978 15.0999 6.93978 14.8399 6.93978 11.6499C6.92067 11.2895 6.97856 10.9292 7.10961 10.593C7.24066 10.2567 7.44185 9.95229 7.69978 9.6999C7.45553 8.968 7.48394 8.1725 7.77978 7.4599C8.45978 7.2399 10.0098 8.3499 10.0098 8.3499C11.334 7.97643 12.7356 7.97643 14.0598 8.3499C14.0598 8.3499 15.6098 7.2399 16.2898 7.4599C16.5911 8.1713 16.6196 8.96881 16.3698 9.6999C16.6373 9.94842 16.8495 10.2505 16.9925 10.5865C17.1355 10.9225 17.2061 11.2848 17.1998 11.6499C17.1998 14.8499 15.2998 15.0999 13.4998 15.3099C13.6807 15.5128 13.8183 15.7505 13.9043 16.0084C13.9903 16.2663 14.0228 16.539 13.9998 16.8099V19.5799C13.9991 19.6474 14.0148 19.7141 14.0454 19.7743C14.076 19.8345 14.1207 19.8864 14.1756 19.9257C14.2306 19.9649 14.2942 19.9904 14.3611 19.9998C14.428 20.0092 14.4961 20.0024 14.5598 19.9799C16.181 19.3977 17.5784 18.3209 18.5545 16.9016C19.5306 15.4822 20.0362 13.7921 19.9998 12.0699C20.0092 11.005 19.8059 9.9489 19.4018 8.96359C18.9977 7.97828 18.4009 7.08357 17.6464 6.33193C16.892 5.58029 15.9951 4.98684 15.0083 4.58639C14.0215 4.18594 12.9647 3.98654 11.8998 3.9999ZM7.13978 15.4099V15.5799C7.15093 15.5911 7.16418 15.6 7.17877 15.606C7.19335 15.6121 7.20899 15.6152 7.22478 15.6152C7.24058 15.6152 7.25622 15.6121 7.2708 15.606C7.28539 15.6 7.29864 15.5911 7.30978 15.5799C7.30978 15.5799 7.30978 15.4699 7.30978 15.3999C7.30978 15.3299 7.17978 15.3699 7.13978 15.4099ZM6.78978 15.1399C6.78978 15.1399 6.78978 15.2399 6.85978 15.2699C6.86822 15.2803 6.87889 15.2888 6.891 15.2945C6.90311 15.3003 6.91636 15.3033 6.92978 15.3033C6.94321 15.3033 6.95646 15.3003 6.96857 15.2945C6.98068 15.2888 6.99135 15.2803 6.99978 15.2699C6.99978 15.2699 6.99978 15.1699 6.92978 15.1399C6.85978 15.1099 6.80978 15.1099 6.78978 15.1399ZM7.78978 16.3199V16.5299C7.78978 16.5999 7.95978 16.6099 7.99978 16.5299C8.03978 16.4499 7.99978 16.3899 7.99978 16.3199C7.99978 16.2499 7.86978 16.2699 7.82978 16.3199H7.78978ZM7.41978 15.8299V16.0299C7.41978 16.1099 7.55978 16.1399 7.60978 16.1099C7.63511 16.0808 7.64906 16.0435 7.64906 16.0049C7.64906 15.9663 7.63511 15.929 7.60978 15.8999C7.55978 15.8199 7.47978 15.7899 7.41978 15.8299Z",fill:"currentColor"})})})]})]})]})]}),(0,s.jsx)("button",{style:{position:"fixed",right:30,bottom:30,zIndex:1e3,width:50,height:50,border:"none",borderRadius:25,boxShadow:"0 2px 10px rgba(0, 0, 0, 0.1)",cursor:"pointer",backgroundColor:"white"},onClick:()=>t(e=>"en"===e?"zh":"en"),children:"en"===e?"中":"En"})]})}}},e=>{e.O(0,[766,441,964,358],()=>e(e.s=3077)),_N_E=e.O()}]);